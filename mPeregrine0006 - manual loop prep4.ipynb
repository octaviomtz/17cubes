{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep categorical cross entropy, try RMSprop for optimizer      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gSize=6\n",
    "dropoutGrid = np.random.uniform(0,.4, gSize)     #param1\n",
    "LRGrid = 10 ** np.random.uniform(-6, 0, gSize)   #param2\n",
    "L2penal1Grid = 10 ** np.random.uniform(-5, 0, gSize)  #param3\n",
    "L2penal2Grid = 10 ** np.random.uniform(-5, 0, gSize)   #param4\n",
    "optimizerGrid=['adam','RMSprop']   #param5\n",
    "activationsGrid=['relu','elu']   #param6\n",
    "neurons1=3**np.random.uniform(1,4,gSize)   #param7\n",
    "neurons1Grid=[np.floor(i) for i in neurons1]\n",
    "neurons2=3**np.random.uniform(1,4,gSize)   #param8\n",
    "neurons2Grid=[np.floor(i) for i in neurons2]\n",
    "neurons3=3**np.random.uniform(1,4,gSize)   #param9\n",
    "neurons3Grid=[np.floor(i) for i in neurons3]\n",
    "miniBatches=np.random.uniform(4,50,gSize)\n",
    "miniBatchGrid=[np.floor(i) for i in miniBatches] #param12\n",
    "\n",
    "kernelsLayer1=3**np.random.uniform(1,4,gSize)   \n",
    "kernelsLayer1Grid=[np.floor(i) for i in kernelsLayer1] #param10\n",
    "\n",
    "ratioBetweenKernels=np.random.uniform(1,2)   \n",
    "kernelslay2=kernelsLayer1*ratioBetweenKernels\n",
    "kernelsLayer2Grid=([np.floor(i) for i in kernelslay2])#param11\n",
    "\n",
    "print (gSize**6)*2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixN=(gSize**6)*2*2\n",
    "print(np.arange(len(dropoutGrid)))\n",
    "print(np.arange(len(LRGrid)))\n",
    "print(np.arange(len(L2penal1Grid)))\n",
    "print(np.arange(len(optimizerGrid)))\n",
    "print(np.arange(len(activationsGrid)))\n",
    "print(np.arange(len(neurons1Grid)))\n",
    "print(np.arange(len(miniBatchGrid)))\n",
    "print(np.arange(len(kernelsLayer1Grid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ratioBetweenKernels\n",
    "for idx, i in enumerate(kernelsLayer1):\n",
    "    print kernelsLayer1Grid[idx], kernelsLayer2Grid[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelName='p0006'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "##\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Merge\n",
    "from keras.layers.convolutional import Convolution3D\n",
    "from keras.layers.pooling import MaxPooling3D\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "from keras.layers import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "##\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import  accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "\n",
    "def readScan(scan):\n",
    "    # We read the file saved in Matlab. There is only one variable in the file called scansMini\n",
    "    data = h5py.File(scan, 'r')\n",
    "    Xscans=data.get('scansMini')\n",
    "    # We have to get the values into the right format (subjects, dim1, dim2, dim3, channels)\n",
    "    X=copy.copy(Xscans.value)\n",
    "    X=np.expand_dims(X,4)\n",
    "    X1=np.rollaxis(X,3)\n",
    "    return X1\n",
    "    \n",
    "############\n",
    "\n",
    "def readLabels(labels):\n",
    "    data = h5py.File(labels, 'r')\n",
    "    Xscans=data.get('labels')\n",
    "    X=copy.copy(Xscans.value)\n",
    "    X2=np.squeeze(X).astype(int)\n",
    "    X3= np.zeros((len(X2), 2))\n",
    "    X3[np.arange(len(X2)), X2] = 1\n",
    "    return X3\n",
    "    \n",
    "############\n",
    "\n",
    "def getScansFold(foldX,cubesNumber):\n",
    "    foldName='fold{0}'.format(foldX)\n",
    "    XTrain=[]\n",
    "    XTest=[]\n",
    "    for i in (np.arange(cubesNumber)+1):\n",
    "        pathNameTrain=foldName+'/train/scansMiniTrain{0}.mat'.format(i)\n",
    "        pathNameTest=foldName+'/test/scansMiniTest{0}.mat'.format(i)\n",
    "        xtrain=readScan(pathNameTrain)\n",
    "        xtest=readScan(pathNameTest)\n",
    "        XTrain.append(xtrain)\n",
    "        XTest.append(xtest)\n",
    "    pathNameLabelTrain=foldName+'/train/labelsTrain.mat'\n",
    "    pathNameLabelTest=foldName+'/test/labelsTest.mat'\n",
    "    y=readLabels(pathNameLabelTrain)\n",
    "    y_true=readLabels(pathNameLabelTest)\n",
    "    return XTrain, XTest, y, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############\n",
    "\n",
    "def restAllModels():\n",
    "    final_model.reset_states()\n",
    "    model1.reset_states()\n",
    "    model2.reset_states()\n",
    "    model3.reset_states()\n",
    "    model4.reset_states()\n",
    "    model5.reset_states()\n",
    "    model6.reset_states()\n",
    "    model7.reset_states()\n",
    "    model8.reset_states()\n",
    "    model9.reset_states()\n",
    "    model10.reset_states()\n",
    "    model11.reset_states()\n",
    "    model12.reset_states()\n",
    "    model13.reset_states()\n",
    "    model14.reset_states()\n",
    "    model15.reset_states()\n",
    "    model16.reset_states()\n",
    "    model17.reset_states()\n",
    "    \n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def defineModel(adam,conv1aW,conv1bW,conv1aN,conv1aInit,conv1aBorder,conv1aAct,fully1W,fully1N,fully1act,fully1init,\n",
    "fully1drop,fully2N,fully2W,fully2init,fully2act,outInit,outAct,outW,Loss):\n",
    "\n",
    "\n",
    "    ###########\n",
    "\n",
    "    model1=Sequential()\n",
    "    model1.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder, init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation(conv1aAct))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dropout(fully1drop))\n",
    "    model1.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model2=Sequential()\n",
    "    model2.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder,  init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Activation(conv1aAct))\n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dropout(fully1drop))\n",
    "    model2.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model3=Sequential()\n",
    "    model3.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder,  init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model3.add(BatchNormalization())\n",
    "    model3.add(Activation(conv1aAct))\n",
    "    model3.add(Flatten())\n",
    "    model3.add(Dropout(fully1drop))\n",
    "    model3.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model4=Sequential()\n",
    "    model4.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder,  init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model4.add(BatchNormalization())\n",
    "    model4.add(Activation(conv1aAct))\n",
    "    model4.add(Flatten())\n",
    "    model4.add(Dropout(fully1drop))\n",
    "    model4.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model5=Sequential()\n",
    "    model5.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder, init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model5.add(BatchNormalization())\n",
    "    model5.add(Activation(conv1aAct))\n",
    "    model5.add(Flatten())\n",
    "    model5.add(Dropout(fully1drop))\n",
    "    model5.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model6=Sequential()\n",
    "    model6.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder, init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model6.add(BatchNormalization())\n",
    "    model6.add(Activation(conv1aAct))\n",
    "    model6.add(Flatten())\n",
    "    model6.add(Dropout(fully1drop))\n",
    "    model6.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model7=Sequential()\n",
    "    model7.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder,  init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model7.add(BatchNormalization())\n",
    "    model7.add(Activation(conv1aAct))\n",
    "    model7.add(Flatten())\n",
    "    model7.add(Dropout(fully1drop))\n",
    "    model7.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model8=Sequential()\n",
    "    model8.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder, init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model8.add(BatchNormalization())\n",
    "    model8.add(Activation(conv1aAct))\n",
    "    model8.add(Flatten())\n",
    "    model8.add(Dropout(fully1drop))\n",
    "    model8.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model9=Sequential()\n",
    "    model9.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder, init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model9.add(BatchNormalization())\n",
    "    model9.add(Activation(conv1aAct))\n",
    "    model9.add(Flatten())\n",
    "    model9.add(Dropout(fully1drop))\n",
    "    model9.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model10=Sequential()\n",
    "    model10.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder, init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model10.add(BatchNormalization())\n",
    "    model10.add(Activation(conv1aAct))\n",
    "    model10.add(Flatten())\n",
    "    model10.add(Dropout(fully1drop))\n",
    "    model10.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model11=Sequential()\n",
    "    model11.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder, init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model11.add(BatchNormalization())\n",
    "    model11.add(Activation(conv1aAct))\n",
    "    model11.add(Flatten())\n",
    "    model11.add(Dropout(fully1drop))\n",
    "    model11.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model12=Sequential()\n",
    "    model12.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder, init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model12.add(BatchNormalization())\n",
    "    model12.add(Activation(conv1aAct))\n",
    "    model12.add(Flatten())\n",
    "    model12.add(Dropout(fully1drop))\n",
    "    model12.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model13=Sequential()\n",
    "    model13.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder, init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model13.add(BatchNormalization())\n",
    "    model13.add(Activation(conv1aAct))\n",
    "    model13.add(Flatten())\n",
    "    model13.add(Dropout(fully1drop))\n",
    "    model13.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model14=Sequential()\n",
    "    model14.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder, init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model14.add(BatchNormalization())\n",
    "    model14.add(Activation(conv1aAct))\n",
    "    model14.add(Flatten())\n",
    "    model14.add(Dropout(fully1drop))\n",
    "    model14.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model15=Sequential()\n",
    "    model15.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder, init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model15.add(BatchNormalization())\n",
    "    model15.add(Activation(conv1aAct))\n",
    "    model15.add(Flatten())\n",
    "    model15.add(Dropout(fully1drop))\n",
    "    model15.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model16=Sequential()\n",
    "    model16.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder, init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model16.add(BatchNormalization())\n",
    "    model16.add(Activation(conv1aAct))\n",
    "    model16.add(Flatten())\n",
    "    model16.add(Dropout(fully1drop))\n",
    "    model16.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    model17=Sequential()\n",
    "    model17.add(Convolution3D(conv1aN, 3, 3, 3, input_shape=(10, 10, 10, 1), border_mode=conv1aBorder, init=conv1aInit, W_regularizer=l2(conv1aW)))\n",
    "    model17.add(BatchNormalization())\n",
    "    model17.add(Activation(conv1aAct))\n",
    "    model17.add(Flatten())\n",
    "    model17.add(Dropout(fully1drop))\n",
    "    model17.add(Dense(fully1N, init=fully1init, activation=fully1act, W_regularizer=l2(fully1W))) \n",
    "\n",
    "    merged = Merge([model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, model11, model12, model13, model14, model15, model16, model17], mode='concat')\n",
    "    final_model = Sequential()\n",
    "    final_model.add(merged)\n",
    "    final_model.add(Dense(fully2N, init=fully2init, activation=fully2act,W_regularizer=l2(fully2W)))\n",
    "    final_model.add(Dense(2, init=outInit, activation=outAct,W_regularizer=l2(outW)))\n",
    "    final_model.compile(loss=Loss, optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainAndTestNetwork(final_model,modelName,foldX):\n",
    "    acc_train=[]\n",
    "    loss_train=[]\n",
    "    acc_val=[]\n",
    "    loss_val=[]\n",
    "    all_lr=[]\n",
    "    t0 = time.time()\n",
    "\n",
    "    # thresholds\n",
    "    thres1=.80\n",
    "    thres1passed=0\n",
    "    thres2=.90\n",
    "    thres2passed=0\n",
    "    thres3=.93\n",
    "    thres3passed=0\n",
    "    thres4=.96\n",
    "    thres4passed=0\n",
    "    maxAcc=0\n",
    "    maxAccVal=0\n",
    "    countNoIncrease=0\n",
    "    minValLoss=10\n",
    "\n",
    "    iteration=1\n",
    "    while iteration<=2:\n",
    "\n",
    "        history=final_model.fit(XTrain1, y1, validation_split=0.2, nb_epoch=1, batch_size=8,verbose=2)\n",
    "        # Append values\n",
    "        acc_train.append(history.history['acc'])\n",
    "        acc_val.append(history.history['val_acc'])\n",
    "        loss_train.append(history.history['loss'])\n",
    "        loss_val.append(history.history['val_loss'])\n",
    "        all_lr.append(K.get_value(final_model.optimizer.lr))\n",
    "\n",
    "        ## if we have a bad initialization\n",
    "        if acc_val[-1][0] < 0.00001:\n",
    "            iteration=1\n",
    "            print('reset weights')\n",
    "            random.seed(np.random.randint(100))\n",
    "            restAllModels()\n",
    "            acc_train=[]\n",
    "            loss_train=[]\n",
    "            acc_val=[]\n",
    "            loss_val=[]\n",
    "            all_lr=[]\n",
    "            continue\n",
    "\n",
    "        # Compare last iteration vs max value of Acc\n",
    "        if acc_train[-1][0]>maxAcc:\n",
    "            maxAcc=max(acc_train)[0]\n",
    "            maxIt=iteration\n",
    "        else:\n",
    "            countNoIncrease=countNoIncrease+1\n",
    "\n",
    "        if acc_val[-1][0]>maxAccVal:\n",
    "            maxAccVal=max(acc_val)[0]\n",
    "\n",
    "            if acc_val>.93:\n",
    "                #save all\n",
    "                final_model.save('k{0}_{1}_val.h5'.format(modelName,foldX))\n",
    "                K_LR=K.get_value(adam.lr)\n",
    "                nameVal='k{0}_{1}_val.pickle'.format(modelName,foldX)\n",
    "                iterationVal=iteration\n",
    "                with open(nameVal, 'wb') as f:\n",
    "                    pickle.dump([K_LR, acc_train, loss_train, acc_val, loss_val, all_lr, countNoIncrease, maxAcc, maxAccVal, \n",
    "                                 thres1, thres1passed, thres2, thres2passed, thres3, thres3passed, thres4, thres4passed,\n",
    "                                iteration], f)\n",
    "\n",
    "\n",
    "        if loss_val[-1][0]<minValLoss:\n",
    "            minValLoss=min(loss_val)[0]\n",
    "\n",
    "            if acc_val>.93:\n",
    "                final_model.save('k{0}_{1}_loss.h5'.format(modelName,foldX))\n",
    "                #save all\n",
    "                K_LR=K.get_value(adam.lr)\n",
    "                iterationLoss=iteration\n",
    "                #nameAndIter='p{0}_loss_{1}.pickle'.format(modelName,iteration)\n",
    "                nameLoss='k{0}_{1}_loss.pickle'.format(modelName,foldX)\n",
    "                with open(nameLoss, 'wb') as f:\n",
    "                    pickle.dump([K_LR, acc_train, loss_train, acc_val, loss_val, all_lr, countNoIncrease, maxAcc, maxAccVal, \n",
    "                                 thres1, thres1passed, thres2, thres2passed, thres3, thres3passed, thres4, thres4passed,\n",
    "                                iteration], f)\n",
    "\n",
    "\n",
    "        if countNoIncrease>=10:\n",
    "            countNoIncrease=0\n",
    "            K.set_value(final_model.optimizer.lr, 0.5 * K.get_value(final_model.optimizer.lr))    \n",
    "\n",
    "        if acc_train[-1][0] > thres1 and thres1passed == 0:\n",
    "            thres1passed=1\n",
    "            countNoIncrease=0\n",
    "            K.set_value(final_model.optimizer.lr, 0.5 * K.get_value(final_model.optimizer.lr))    \n",
    "\n",
    "        if acc_train[-1][0] > thres2 and thres2passed == 0:\n",
    "            thres2passed=1\n",
    "            countNoIncrease=0\n",
    "            K.set_value(final_model.optimizer.lr, 0.5 * K.get_value(final_model.optimizer.lr))    \n",
    "\n",
    "        if acc_train[-1][0] > thres3 and thres3passed == 0:\n",
    "            thres3passed=1\n",
    "            countNoIncrease=0\n",
    "            K.set_value(final_model.optimizer.lr, 0.5 * K.get_value(final_model.optimizer.lr))    \n",
    "\n",
    "        if acc_train[-1][0] > thres4 and thres4passed == 0:\n",
    "            thres4passed=1\n",
    "            countNoIncrease=0\n",
    "            K.set_value(final_model.optimizer.lr, 0.5 * K.get_value(final_model.optimizer.lr))   \n",
    "\n",
    "        iteration+=1\n",
    "\n",
    "    t1 = time.time()\n",
    "    print (t1-t0)/60/60\n",
    "\n",
    "    ###########\n",
    "    # test best model according to val_acc\n",
    "    best_model=load_model('k{0}_{1}_val.h5'.format(modelName,foldX))\n",
    "    y_pred=best_model.predict_classes(XTest1)\n",
    "    y_predC=np.squeeze(y_pred)  \n",
    "    y_predProb=final_model.predict(XTest1)\n",
    "    y_predP=np.squeeze(y_predProb)\n",
    "\n",
    "    testAcc=accuracy_score(y_true1[:,1],y_predC)\n",
    "    testWrong=np.where(y_true1[:,1].astype(bool)!=y_predC.astype(bool))[0]\n",
    "    testMatrix=confusion_matrix(y_true1[:,1],y_predC)\n",
    "\n",
    "    ##########\n",
    "\n",
    "    df1=pd.DataFrame(acc_train,columns=['acc_train_{0}'.format(foldX)])\n",
    "    df2=pd.DataFrame(acc_val,columns=['acc_val_{0}'.format(foldX)])\n",
    "    df3=pd.DataFrame(loss_train,columns=['loss_train_{0}'.format(foldX)])\n",
    "    df4=pd.DataFrame(loss_val,columns=['loss_val_{0}'.format(foldX)])\n",
    "    df5=pd.DataFrame([iteration],columns=['iteration_{0}'.format(foldX)])\n",
    "    df6=pd.DataFrame([iterationVal],columns=['iterationVal_{0}'.format(foldX)])\n",
    "    df7=pd.DataFrame([iterationLoss],columns=['iterationLoss_{0}'.format(foldX)])\n",
    "    df8=pd.DataFrame(all_lr,columns=['learningRate_{0}'.format(foldX)])\n",
    "    df9=pd.DataFrame([testAcc],columns=['testAcc_{0}'.format(foldX)])\n",
    "\n",
    "    outResults=pd.concat([df1,df2, df3, df4, df5, df6, df7, df8, df9],axis=1)\n",
    "    wrongPredictions=pd.DataFrame(testWrong,columns=['wrongPredictions_{0}'.format(foldX)])\n",
    "    confusionMatrix=pd.DataFrame(testMatrix,columns=['0','1'])\n",
    "    predictionsC=pd.DataFrame(y_predC,columns=['predClasses_{0}'.format(foldX)])\n",
    "    predictionsP=pd.DataFrame(y_predP[:,1],columns=['predProba_{0}'.format(foldX)])\n",
    "    predictions=pd.concat([predictionsC,predictionsP],axis=1)\n",
    "\n",
    "    #outResults.to_csv('outResults_{0}.csv'.format(modelName), index=False)\n",
    "    #wrongPredictions.to_csv('wrongPredictions_{0}.csv'.format(modelName), index=False)\n",
    "    #confusionMatrix.to_csv('confusionMatrix_{0}.csv'.format(modelName), index=False)\n",
    "    #predictions.to_csv('predictions_{0}.csv'.format(modelName), index=False)\n",
    "    \n",
    "    return outResults, wrongPredictions, confusionMatrix, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 198 samples, validate on 50 samples\n",
      "Epoch 1/1\n",
      "258s - loss: 6.9783 - acc: 0.5606 - val_loss: 2.7466 - val_acc: 0.3200\n",
      "Train on 198 samples, validate on 50 samples\n",
      "Epoch 1/1\n",
      "275s - loss: 5.9568 - acc: 0.5859 - val_loss: 1.8402 - val_acc: 0.3200\n",
      "0.170167430043\n",
      "62/62 [==============================] - 6s     \n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "foldX=1\n",
    "cubesNumber=17\n",
    "\n",
    "XTrain1, XTest1, y1, y_true1 = getScansFold(foldX,cubesNumber)\n",
    "adam=Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-04)\n",
    "conv1aW=0.05\n",
    "conv1bW=0.05\n",
    "conv1aN=20\n",
    "conv1aInit='he_normal'\n",
    "conv1aBorder='valid'\n",
    "conv1aAct='relu'\n",
    "fully1W=0.0\n",
    "fully1N=20\n",
    "fully1act='tanh'\n",
    "fully1init='glorot_normal'\n",
    "fully1drop=0.2\n",
    "fully2N=10\n",
    "fully2W=.01\n",
    "fully2init='glorot_normal'\n",
    "fully2act='tanh'\n",
    "outInit='glorot_normal'\n",
    "outAct='softmax'\n",
    "outW=.05\n",
    "Loss='categorical_crossentropy'\n",
    "final_model1=defineModel(adam,conv1aW,conv1bW,conv1aN,conv1aInit,conv1aBorder,conv1aAct,fully1W,fully1N,fully1act,fully1init,\n",
    "fully1drop,fully2N,fully2W,fully2init,fully2act,outInit,outAct,outW,Loss)\n",
    "outResults, wrongPredictions, confusionMatrix, predictions = trainAndTestNetwork(final_model1,modelName,foldX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train_1</th>\n",
       "      <th>acc_val_1</th>\n",
       "      <th>loss_train_1</th>\n",
       "      <th>loss_val_1</th>\n",
       "      <th>iteration_1</th>\n",
       "      <th>iterationVal_1</th>\n",
       "      <th>iterationLoss_1</th>\n",
       "      <th>learningRate_1</th>\n",
       "      <th>testAcc_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.32</td>\n",
       "      <td>6.978296</td>\n",
       "      <td>2.746575</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.532258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.32</td>\n",
       "      <td>5.956763</td>\n",
       "      <td>1.840207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_train_1  acc_val_1  loss_train_1  loss_val_1  iteration_1  \\\n",
       "0     0.560606       0.32      6.978296    2.746575            3   \n",
       "1     0.585859       0.32      5.956763    1.840207          NaN   \n",
       "\n",
       "   iterationVal_1  iterationLoss_1  learningRate_1  testAcc_1  \n",
       "0               1                2          0.0005   0.532258  \n",
       "1             NaN              NaN          0.0005        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0243457a10>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEACAYAAACtVTGuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f024f384210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(all_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
